一个大魔王的狗哥:
遇到一个很有意思的问题，同样的数据我用libsvm 格式训练lr， auc很高，用numpy的array训练auc只有最惨的0.5， 但是换成xg+lr， array的auc就会更好一点。

爱吃炸鸡的猪:
@狗哥 推荐  - 上海某公司 你的训练数据里面是不是有category类的特征

一个大魔王的狗哥:
「 爱吃炸鸡的猪: @狗哥 推荐  - 上海某公司 你的训练数据里面是不是有category类的特征 」
- - - - - - - - - - - - - - -
对 会有影响吗

爱吃炸鸡的猪:
对的

爱吃炸鸡的猪:
而且 这部分category的特征 跑出来应该重要性不低吧

一个大魔王的狗哥:
我是把category特征，做了映射。。

一个大魔王的狗哥:
嗯 对 重要性挺高的

爱吃炸鸡的猪:
lightgbm 不用你人为做 她会采用更适合数据的方式帮你做

爱吃炸鸡的猪:
你提供的三个方案

爱吃炸鸡的猪:
效果好的两个 一个是lightgbm做了这个处理 xg相当于用模型学到了这部分特征

一个大魔王的狗哥:
category特征对lr的影响该怎么解释啊

爱吃炸鸡的猪:
如果已经做了dummy的处理 那么就逐个解释 如果放在一起 可以按照 本身是否有序 这种思路解释

一个大魔王的狗哥:
「 爱吃炸鸡的猪: 如果已经做了dummy的处理 那么就逐个解释 如果放在一起 可以按照 本身是否有序 这种思路解释 」
- - - - - - - - - - - - - - -
可以理解成 category特征重要性高，但是分类效果不好吗

爱吃炸鸡的猪:
不是 是你的特征对于用xg 模型来说 处理的不好

一个大魔王的狗哥:
用xg还可以啊 纯lr 不好

爱吃炸鸡的猪:
写错了

爱吃炸鸡的猪:
lr 需要线性关系

一个大魔王的狗哥:
对 所以我好奇为什么用libsvm格式的数据 就numpy的就不好

爱吃炸鸡的猪:
你确定这两份数据是一样的么 你用libsvm格式 也不能直接放到lr里面吧

一个大魔王的狗哥:
「 爱吃炸鸡的猪: 你确定这两份数据是一样的么 你用libsvm格式 也不能直接放到lr里面吧 」
- - - - - - - - - - - - - - -
可以啊 sklearn里面lr，支持的，两份数据是一样的

爱吃炸鸡的猪:
我没记错的话 libsvm是 id:value 这样的格式

爱吃炸鸡的猪:
你需要取出value 放到lr 里面吧

爱吃炸鸡的猪:
如果这样的话 特征 维度一样 值一样 即使有sgd 或者其他随机因素 相同的lr 不会差异那么大

一个大魔王的狗哥:
sklearn 会自动处理 libsvm格式，训练结果有差异我没搞清楚，还得再试试
